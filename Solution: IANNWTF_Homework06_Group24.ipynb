{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IANNWTF_Homework06_Group26.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP2M6A4+GsuPa8OupWxFGrF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pravallika41296/IANNWTF_Homework_Group24/blob/main/Solution%3A%20IANNWTF_Homework06_Group24.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jndCDCixBla4"
      },
      "source": [
        "#Importing all the necessary packages\r\n",
        "import numpy as np\r\n",
        "%tensorflow_version 2.x\r\n",
        "import tensorflow as tf\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from tensorflow.keras import Model\r\n",
        "from tensorflow.keras.layers import Layer\r\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9hUdiCFrv6u"
      },
      "source": [
        "#Loading the dataset\r\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vccpZ3LrZD-c"
      },
      "source": [
        "\r\n",
        "batch_size = 64\r\n",
        "\r\n",
        "# Creates tensorflow datasets for the training and test data.\r\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\r\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\r\n",
        "\r\n",
        "# Conducts the normalization of the inputs (images) and the one-hot-encoding of the targets.\r\n",
        "train_dataset = train_dataset.map(lambda inp, tar: ((2*(inp/255)-1), tf.one_hot(tar, 10)))  # tf.squeeze(tar) to remove dimensions of size 1 from the shape of the target-tensors.\r\n",
        "test_dataset = test_dataset.map(lambda inp, tar: ((2*(inp/255)-1), tf.one_hot(tar, 10)))     \r\n",
        "                                                                                          \r\n",
        "# Batches, shuffles and prefetches the training- and test datasets.\r\n",
        "train_dataset = train_dataset.batch(batch_size).shuffle(buffer_size = batch_size).prefetch(128)\r\n",
        "test_dataset = test_dataset.batch(batch_size).shuffle(buffer_size = batch_size).prefetch(128)\r\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dabixaMIZG_r",
        "outputId": "437fdd0c-8324-4b90-ffe3-b37d17188755"
      },
      "source": [
        "#Checking the dimensions of the \r\n",
        "for (img,label) in train_dataset:\r\n",
        "    print(label.shape)# the first dimension is the batch size / number of inputs\r\n",
        "    break;"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 1, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ffu2UalZbCIs"
      },
      "source": [
        "class ResidualBlock(tf.keras.layers.Layer):\r\n",
        "  \r\n",
        "  def __init__(self, channels):\r\n",
        "    super(ResidualBlock, self).__init__()\r\n",
        "\r\n",
        "    self.conv1 = tf.keras.layers.Conv2D(filters=channels, kernel_size=1, padding='SAME', activation='relu',\r\n",
        "                                        input_shape=(32,32,3))\r\n",
        "    self.bn1 =  tf.keras.layers.BatchNormalization()\r\n",
        "           \r\n",
        "    self.conv2 = tf.keras.layers.Conv2D(filters=channels, kernel_size=3, padding='SAME',activation='relu')\r\n",
        "    self.bn2 =  tf.keras.layers.BatchNormalization()\r\n",
        "\r\n",
        "    self.conv3 = tf.keras.layers.Conv2D(filters=channels, kernel_size=1, padding='SAME', activation='relu')\r\n",
        "    self.bn3 =  tf.keras.layers.BatchNormalization()\r\n",
        "\r\n",
        "  @tf.function\r\n",
        "  def call(self, x, training):\r\n",
        "\r\n",
        "    # define call\r\n",
        "    # add original input to block output\r\n",
        "    y = self.conv1(x)\r\n",
        "    y = self.bn1(y, training = training)\r\n",
        "    y = self.conv2(y)\r\n",
        "    y = self.bn2(y, training = training)\r\n",
        "    y = self.conv3(y)\r\n",
        "    y = self.bn3(y, training = training)\r\n",
        "\r\n",
        "    y = y + x\r\n",
        "    return y\r\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvWX4QlQeLGO"
      },
      "source": [
        "class ResNet(tf.keras.Model):\r\n",
        "\r\n",
        "  def __init__(self, num_blocks=25, channels_in_block=3):\r\n",
        "\r\n",
        "    super(ResNet, self).__init__()\r\n",
        "\r\n",
        "    # you can define a set of layes to put in front of the Residual blocks\r\n",
        "    self.pre_block = [tf.keras.layers.Conv2D(filters=channels_in_block, kernel_size=3, padding='SAME', activation= \"relu\")]\r\n",
        "    self.pre_block.append(tf.keras.layers.BatchNormalization())\r\n",
        "\r\n",
        "    # now you can use your self defined blocks much like layers\r\n",
        "    self.blocks = []\r\n",
        "    for _ in range(num_blocks):\r\n",
        "        self.blocks.append(ResidualBlock(channels=channels_in_block))\r\n",
        "\r\n",
        "    self.post_blocks = []\r\n",
        "    self.post_blocks.append(tf.keras.layers.GlobalAveragePooling2D())\r\n",
        "    self.post_blocks.append(tf.keras.layers.Dense(units=10, activation = \"softmax\"))\r\n",
        "\r\n",
        "  @tf.function\r\n",
        "  def call(self, x, training_flag):\r\n",
        "      # pass input through pre_block layers\r\n",
        "      # you can pass the training flag to every layer in tf\r\n",
        "    for layer in self.pre_block:\r\n",
        "      x = layer(x, training=training_flag)     \r\n",
        "    y = x\r\n",
        "    for b in self.blocks:\r\n",
        "      y = b(y)\r\n",
        "     # readout layers\r\n",
        "    for b in self.post_blocks:\r\n",
        "      y = b(y)\r\n",
        "    # make sure prediction and target dimension match\r\n",
        "    y = tf.expand_dims(y, axis=1)\r\n",
        "    return y"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ml6bYj40bwE"
      },
      "source": [
        "class ConvBlock(tf.keras.layers.Layer):\r\n",
        "    def __init__(self, num_channels):\r\n",
        "        super(ConvBlock, self).__init__()\r\n",
        "        self.bn = tf.keras.layers.BatchNormalization()\r\n",
        "        self.relu = tf.keras.layers.ReLU()\r\n",
        "        self.conv = tf.keras.layers.Conv2D(\r\n",
        "            filters=num_channels, kernel_size=(3, 3), padding='same', activation = 'relu')\r\n",
        "\r\n",
        "        self.listLayers = [self.bn, self.relu, self.conv]\r\n",
        "\r\n",
        "    def call(self, x, training):\r\n",
        "        y = x\r\n",
        "        for layer in self.listLayers.layers:\r\n",
        "            y = layer(y, training = training)\r\n",
        "        y = tf.keras.layers.concatenate([x,y], axis=-1)\r\n",
        "        return y"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtXBuy0qujXn"
      },
      "source": [
        "class DenseBlock(tf.keras.layers.Layer):\r\n",
        "    def __init__(self, num_convs, num_channels):\r\n",
        "        super(DenseBlock, self).__init__()\r\n",
        "        self.listLayers = []\r\n",
        "        for _ in range(num_convs):\r\n",
        "            self.listLayers.append(ConvBlock(num_channels))\r\n",
        "\r\n",
        "    def call(self, x):\r\n",
        "        for layer in self.listLayers.layers:\r\n",
        "            x = layer(x)\r\n",
        "        return x"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5slbqsX0sBm"
      },
      "source": [
        "class TransitionBlock(tf.keras.layers.Layer):\r\n",
        "    def __init__(self, num_channels, **kwargs):\r\n",
        "        super(TransitionBlock, self).__init__(**kwargs)\r\n",
        "        self.batch_norm = tf.keras.layers.BatchNormalization()\r\n",
        "        self.relu = tf.keras.layers.ReLU()\r\n",
        "        self.conv = tf.keras.layers.Conv2D(num_channels, kernel_size=1)\r\n",
        "        self.avg_pool = tf.keras.layers.AvgPool2D(pool_size=2, strides=2)\r\n",
        "\r\n",
        "    def call(self, x, training):\r\n",
        "        x = self.batch_norm(x, training = training)\r\n",
        "        x = self.relu(x)\r\n",
        "        x = self.conv(x)\r\n",
        "        return self.avg_pool(x)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWEuPi2ku3EL"
      },
      "source": [
        "class DenseNet(tf.keras.Model):\r\n",
        "  def __init__(self, channels_in_block=3):\r\n",
        "    super(DenseNet, self).__init__()\r\n",
        "\r\n",
        "    # you can define a set of layes to put in front of the Residual blocks\r\n",
        "    self.pre_block = [tf.keras.layers.Conv2D(filters=channels_in_block, kernel_size=3, padding='SAME')]\r\n",
        "    self.pre_block.append(tf.keras.layers.BatchNormalization())\r\n",
        "    self.blocks = []\r\n",
        "    num_channels, growth_rate = 3 , 32\r\n",
        "    num_convs_in_dense_blocks = [4, 4]\r\n",
        "\r\n",
        "    for i, num_convs in enumerate(num_convs_in_dense_blocks):\r\n",
        "        self.blocks.append((DenseBlock(num_convs, growth_rate)))\r\n",
        "        # This is the number of output channels in the previous dense block\r\n",
        "        num_channels += num_convs * growth_rate\r\n",
        "        # A transition layer that haves the number of channels is added\r\n",
        "        # between the dense blocks\r\n",
        "        if i != len(num_convs_in_dense_blocks) - 1:\r\n",
        "            num_channels //= 2\r\n",
        "            self.blocks.append((TransitionBlock(num_channels)))\r\n",
        "\r\n",
        "    self.post_blocks = []\r\n",
        "    self.post_blocks.append(tf.keras.layers.GlobalAveragePooling2D())\r\n",
        "    self.post_blocks.append(tf.keras.layers.Dense(units=10, activation = \"softmax\"))\r\n",
        "    # now you can use your self defined blocks much like layers\r\n",
        "\r\n",
        "  @tf.function\r\n",
        "  def call(self, x, training_flag):\r\n",
        "      # pass input through pre_block layers\r\n",
        "      # you can pass the training flag to every layer in tf\r\n",
        "    for layer in self.pre_block:\r\n",
        "      x = layer(x, training=training_flag)     \r\n",
        "    y = x\r\n",
        "    for b in self.blocks:\r\n",
        "      y = b(y)\r\n",
        "     # readout layers\r\n",
        "    for b in self.post_blocks:\r\n",
        "      y = b(y)\r\n",
        "    # make sure prediction and target dimension match\r\n",
        "    y = tf.expand_dims(y, axis=1)\r\n",
        "    return y"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUSjLpmppa5U"
      },
      "source": [
        "def timing(start):\r\n",
        "    now = time.time()\r\n",
        "    time_per_training_step = now - start\r\n",
        "    # compute duration of an epoch\r\n",
        "    return round(time_per_training_step, 2)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjL-9XNapuLB"
      },
      "source": [
        "#Function for the accuracy measure \r\n",
        "def acc_metric(target,output):\r\n",
        "    acc = np.argmax(target, axis=2) == np.argmax(output, axis=2) \r\n",
        "    acc = np.mean(acc)\r\n",
        "    return acc"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BC_8tmiDpw5J"
      },
      "source": [
        "#Defining the training and testing functions\r\n",
        "def train_step(model, input, target, loss_function, optimizer, training = True):\r\n",
        "\r\n",
        "  with tf.GradientTape() as tape:\r\n",
        "    prediction = model(input, training)\r\n",
        "    loss = loss_function(target, prediction) \r\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\r\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\r\n",
        "  return loss \r\n",
        "\r\n",
        "def test(model, test_data, loss_function, training =False):\r\n",
        "  # test over complete test data\r\n",
        "\r\n",
        "  test_accuracy_aggregator = []\r\n",
        "  test_loss_aggregator = []\r\n",
        "\r\n",
        "  for (input, target) in test_data:\r\n",
        "    prediction = model(input, training)\r\n",
        "    sample_test_loss = loss_function(target, prediction)\r\n",
        "    sample_test_accuracy =  acc_metric(target, prediction)\r\n",
        "\r\n",
        "    test_loss_aggregator.append(sample_test_loss.numpy())\r\n",
        "    test_accuracy_aggregator.append(sample_test_accuracy)\r\n",
        "\r\n",
        "  test_loss = np.mean(test_loss_aggregator)\r\n",
        "  test_accuracy = np.mean(test_accuracy_aggregator)\r\n",
        "\r\n",
        "  return test_loss, test_accuracy"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPTH243wp3X4",
        "outputId": "0cc053e4-3896-41b6-9742-cacdd3680911"
      },
      "source": [
        "tf.keras.backend.clear_session()\r\n",
        "\r\n",
        "### Hyperparameters\r\n",
        "num_epochs = 30\r\n",
        "learning_rate = 0.001\r\n",
        "running_average_factor = 0.95\r\n",
        "\r\n",
        "# Initialize the model.\r\n",
        "ResNetmodel = ResNet()\r\n",
        "DenseNetmodel = DenseNet()\r\n",
        "# Initialize the loss: categorical cross entropy\r\n",
        "cross_entropy_loss = tf.keras.losses.CategoricalCrossentropy()\r\n",
        "# Initialize the optimizer: Adam\r\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate)\r\n",
        "\r\n",
        "# Initialize lists for later visualization.\r\n",
        "Rtrain_losses = []\r\n",
        "Dtrain_losses = []\r\n",
        "Rtest_losses = []\r\n",
        "Rtest_accuracies = []\r\n",
        "Dtest_losses = []\r\n",
        "Dtest_accuracies = []\r\n",
        "\r\n",
        "#testing once before we begin\r\n",
        "#test_loss, test_accuracy = test(model, test_dataset, cross_entropy_loss)\r\n",
        "#test_losses.append(test_loss)\r\n",
        "#test_accuracies.append(test_accuracy)\r\n",
        "\r\n",
        "#check how model performs on train data once before we begin\r\n",
        "#train_loss, _ = test(model, train_dataset, cross_entropy_loss)\r\n",
        "#train_losses.append(train_loss)\r\n",
        "\r\n",
        "\r\n",
        "# We train for num_epochs epochs.\r\n",
        "for epoch in range(num_epochs):\r\n",
        "    print('Epoch: __ ' + str(epoch))\r\n",
        "\r\n",
        "    #training (and checking in with training)\r\n",
        "    Raverage = []\r\n",
        "    start = time.time()\r\n",
        "    for (image,target) in train_dataset:\r\n",
        "      Rtrain_loss = train_step(ResNetmodel, image , target, cross_entropy_loss, optimizer)\r\n",
        "      Raverage.append(Rtrain_loss)   \r\n",
        "\r\n",
        "    print(f\"ResNet :The training step took {timing(start)} seconds\")       \r\n",
        "    Rtrain_losses.append(np.mean(Raverage))\r\n",
        "\r\n",
        "     #testing\r\n",
        "    Rtest_loss, Rtest_accuracy = test(ResNetmodel, train_dataset, cross_entropy_loss)\r\n",
        "    Rtest_losses.append(Rtest_loss)\r\n",
        "    Rtest_accuracies.append(Rtest_accuracy)\r\n",
        "    print('ResNet: Test Accuracy: ', Rtest_accuracy)\r\n",
        "    print('ResNet: Test Loss: ', Rtest_losses)\r\n",
        "\r\n",
        "for epoch in range(num_epochs):\r\n",
        "    print('Epoch: __ ' + str(epoch))\r\n",
        "\r\n",
        "    #training (and checking in with training)\r\n",
        "    Daverage = []\r\n",
        "    Dstart = time.time()\r\n",
        "    for (image,target) in train_dataset:\r\n",
        "        Dtrain_loss = train_step(DenseNetmodel, image , target, cross_entropy_loss, optimizer)\r\n",
        "        Daverage.append(Dtrain_loss)   \r\n",
        "\r\n",
        "    print(f\" DenseNet :The training step took {timing(Dstart)} seconds\")       \r\n",
        "    Dtrain_losses.append(np.mean(Daverage))\r\n",
        "      \r\n",
        "    \r\n",
        "    #testing\r\n",
        "    Dtest_loss, Dtest_accuracy = test(DenseNetmodel, test_dataset, cross_entropy_loss)\r\n",
        "    Dtest_losses.append(Dtest_loss)\r\n",
        "    Dtest_accuracies.append(Dtest_accuracy)\r\n",
        "    print(' DenseNet: Test Accuracy: ', Dtest_accuracy)\r\n",
        "    print(' DenseNet: Test loss: ', Dtest_losses)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: __ 0\n",
            "ResNet :The training step took 70.21 seconds\n",
            "ResNet: Test Accuracy:  0.2952365728900256\n",
            "ResNet: Test Loss:  [1.8544962]\n",
            "Epoch: __ 1\n",
            "ResNet :The training step took 60.98 seconds\n",
            "ResNet: Test Accuracy:  0.32864450127877237\n",
            "ResNet: Test Loss:  [1.8544962, 1.7239622]\n",
            "Epoch: __ 2\n",
            "ResNet :The training step took 61.03 seconds\n",
            "ResNet: Test Accuracy:  0.34738650895140666\n",
            "ResNet: Test Loss:  [1.8544962, 1.7239622, 1.6610869]\n",
            "Epoch: __ 3\n",
            "ResNet :The training step took 61.44 seconds\n",
            "ResNet: Test Accuracy:  0.3692455242966752\n",
            "ResNet: Test Loss:  [1.8544962, 1.7239622, 1.6610869, 1.6071253]\n",
            "Epoch: __ 4\n",
            "ResNet :The training step took 61.09 seconds\n",
            "ResNet: Test Accuracy:  0.3640105498721228\n",
            "ResNet: Test Loss:  [1.8544962, 1.7239622, 1.6610869, 1.6071253, 1.6167238]\n",
            "Epoch: __ 5\n",
            "ResNet :The training step took 61.43 seconds\n",
            "ResNet: Test Accuracy:  0.3672874040920716\n",
            "ResNet: Test Loss:  [1.8544962, 1.7239622, 1.6610869, 1.6071253, 1.6167238, 1.6040835]\n",
            "Epoch: __ 6\n",
            "ResNet :The training step took 60.66 seconds\n",
            "ResNet: Test Accuracy:  0.3862292199488491\n",
            "ResNet: Test Loss:  [1.8544962, 1.7239622, 1.6610869, 1.6071253, 1.6167238, 1.6040835, 1.5570362]\n",
            "Epoch: __ 7\n",
            "ResNet :The training step took 61.23 seconds\n",
            "ResNet: Test Accuracy:  0.39010549872122763\n",
            "ResNet: Test Loss:  [1.8544962, 1.7239622, 1.6610869, 1.6071253, 1.6167238, 1.6040835, 1.5570362, 1.5451267]\n",
            "Epoch: __ 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lz2kdG7vuBgb",
        "outputId": "3ce3b009-60bc-41ab-bb47-d568759e4311"
      },
      "source": [
        "ResNetmodel.summary()\r\n",
        "DenseNetmodel.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"res_net\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              multiple                  84        \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo multiple                  12        \n",
            "_________________________________________________________________\n",
            "residual_block (ResidualBloc multiple                  144       \n",
            "_________________________________________________________________\n",
            "residual_block_1 (ResidualBl multiple                  144       \n",
            "_________________________________________________________________\n",
            "residual_block_2 (ResidualBl multiple                  144       \n",
            "_________________________________________________________________\n",
            "residual_block_3 (ResidualBl multiple                  144       \n",
            "_________________________________________________________________\n",
            "residual_block_4 (ResidualBl multiple                  144       \n",
            "_________________________________________________________________\n",
            "residual_block_5 (ResidualBl multiple                  144       \n",
            "_________________________________________________________________\n",
            "residual_block_6 (ResidualBl multiple                  144       \n",
            "_________________________________________________________________\n",
            "residual_block_7 (ResidualBl multiple                  144       \n",
            "_________________________________________________________________\n",
            "residual_block_8 (ResidualBl multiple                  144       \n",
            "_________________________________________________________________\n",
            "residual_block_9 (ResidualBl multiple                  144       \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  40        \n",
            "=================================================================\n",
            "Total params: 1,576\n",
            "Trainable params: 1,390\n",
            "Non-trainable params: 186\n",
            "_________________________________________________________________\n",
            "Model: \"dense_net\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_31 (Conv2D)           multiple                  84        \n",
            "_________________________________________________________________\n",
            "batch_normalization_31 (Batc multiple                  12        \n",
            "_________________________________________________________________\n",
            "dense_block (DenseBlock)     multiple                  59696     \n",
            "_________________________________________________________________\n",
            "transition_block (Transition multiple                  9104      \n",
            "_________________________________________________________________\n",
            "dense_block_1 (DenseBlock)   multiple                  132112    \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              multiple                  1940      \n",
            "=================================================================\n",
            "Total params: 202,948\n",
            "Trainable params: 201,368\n",
            "Non-trainable params: 1,580\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}